_       = require 'underscore'
op      = require 'operator'
ko      = require 'knockout'
Seq     = require 'seq'

{ ReadyEmitter,
} = require 'emitters'

{ Model, StoredModel, ModelCache,
} = require '../../base'
{ ParsingMixin,
} = require '../../util'
{ Dataset,
} = require '../dataset'




/**
 * @class Encapsulates the definition of a column in a DataSource.
 */
class exports.ColumnDef extends Model
    ParsingMixin.mix this
    
    (attributes, @source) -> super ...
    
    defaults: ->
        id    : null
        label : ''
        type  : 'int'
        index : -1
    
    /**
     * Convert the string representation of a value from this Column to
     * its real type.
     * 
     * @param {String} value A serialized value.
     * @returns {*} The value parsed into the appropriate type.
     */
    parse: (value) ->
        @parseValue value, @get 'type'
    


/**
 * @class Metadata representing a source of data, such as a CSV file or
 * a web service endpoint.
 */
class exports.DataSource extends StoredModel
    -> super ...
    
    
    resource : 'datasources'
    getId    : -> @get 'id'
    
    formatContentTypes :
        # format    : Content-Type for AJAX request
        csv         : 'text'
        tsv         : 'text'
        json        : 'json'
        jsonp       : 'jsonp'
        xml         : 'xml'
    
    defaults : ->
        id            : null
        slug          : null
        
        format        : 'json'          # := csv | tsv | json | jsonp | xml                 ContentType/serialization/encoding of the dataset response.
        type          : 'timeseries'    # := series | timeseries | geojson | topojson       Type of the contents of the dataset.
        url           : ''
        
        name          : ''
        shortName     : ''
        desc          : ''
        notes         : ''
        
        columns       : []
        timespan      : { start:null, end:null, step:'1mo' }
    
    attributeTypes: ->
        columns : ColumnDef
    
    
    
    /**
     * Whether this DataSource is valid, and thus ready to load data.
     * @type ko.computed<Boolean>
     */
    isValid : @computed ->
        !! @dataUrl() and @get('format') in @formatContentTypes
    
    
    /**
     * Generates a random number of length around 10
     */
    generateRandom: -> 999999999 + Math.floor(Math.random() * 999999999)
    
    
    /**
     * URL for the data.
     * @type ko.computed<String>
     */
    dataUrl : @computedRequires 'url', (url) ->
        if url.indexOf('http') == 0
            url = "/x/#url"
        cacheBuster = @generateRandom()
        "#url?#cacheBuster"
    
    
    /**
     * Encoding of the dataset response.
     * @type ko.computed<String>
     */
    dataFormat : @computed ->
        format = @get('format')
        unless format
            return format unless url = @get('url')
            # format = /\.([^\.]+)$/.exec(url)?[1] or 'csv'
            format = if url.indexOf('.json') === url.length - 5 then 'json' else 'csv'
        format
    
    
    /**
     * Dataset class wrapping the data.
     * @type ko.computed<Dataset>
     */
    datasetType : @computedRequires 'type', (type) ->
        Dataset.lookupType type
    
    
    /**
     * The reified dataset associated with this DataSource.
     * @type ko.asyncComputed<TimeSeriesData|CSVData>
     * @depends url, format
     */
    data : @asyncComputed ->
        return unless @isValid()
        return unless format      = @dataFormat()
        return unless DatasetType = @datasetType()
        
        xhr = $.ajax do
            url      : @dataUrl()
            dataType : @formatContentTypes[format]
        
        promise = xhr.pipe (data) ~> new DatasetType this, data
        promise.then do
            (data) ~> @trigger 'data-load',  this, data
            (err)  ~> @trigger 'data-error', this
        promise.xhr = xhr
        
        promise
    
    
    /**
     * Enforces backwards compatibility at runtime by converting a DataSource from
     * one of many of the historical "formats" we've used to whatever the modern
     * format looks like.
     * 
     * @param {Object} data Raw DataSource attributes to canonicalize.
     * @returns {Object} Converted raw data.
     */
    canonicalize : (data) ->
        data.slug         or= data.id
        data.shortName    or= data.name
        
        cols = data.columns
        if _.isArray cols
            data.columns = _.map cols, (col, idx) ->
                if _.isArray col
                    [label, type] = col
                    id = _.str.underscored(label.toLowerCase())
                    {id, label, type or 'int'}
                else
                    col.type or= 'int'
                    col
        else
            cols = _.merge { ids:[], types:[] }, cols
            data.columns = _.map cols.labels, (label, idx) ->
                id   = cols.ids[idx]   or _.str.underscored(label.toLowerCase())
                type = cols.types[idx] or 'int'
                {id, idx, label, type}
        data
    
    

