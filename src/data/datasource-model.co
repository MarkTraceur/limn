_       = require 'underscore'
op      = require 'operator'
ko      = require 'knockout'
Seq     = require 'seq'

{ ReadyEmitter,
} = require 'emitters'
{ TimeSeriesData, CSVData,
} = require 'timeseries'

{ Model, StoredModel, ModelCache,
} = require '../base'
{ ParserMixin,
} = require '../util/parser-mixin'




/**
 * @class Encapsulates the definition of a column in a DataSource.
 */
class exports.ColumnDef extends Model
    ParserMixin.mix this
    
    (attributes, @source) -> super ...
    
    defaults: ->
        id    : null
        label : ''
        type  : 'int'
        index : -1
    
    /**
     * Convert the string representation of a value from this Column to
     * its real type.
     * 
     * @param {String} value A serialized value.
     * @returns {*} The value parsed into the appropriate type.
     */
    parse: (value) ->
        @parseValue value, @get 'type'


/**
 * @class Metadata representing a source of data, such as a CSV file or
 * a web service endpoint.
 */
class exports.DataSource extends StoredModel
    VALID_FORMATS : <[ json csv ]>
    
    (attributes={}) -> super attributes
    
    
    resource : 'datasources'
    getId    : -> @get 'id'
    
    defaults : ->
        id            : null
        url           : ''
        format        : 'json'
        
        name          : ''
        shortName     : ''
        title         : ''
        subtitle      : ''
        desc          : ''
        notes         : ''
        
        timespan      : { start:null, end:null, step:'1mo' }
        
        /**
         * @type ColumnDef[]
         */
        columns       : []
    
    attributeTypes :
        columns : ColumnDef
    
    
    /**
     * Whether this DataSource is valid, and thus ready to load data.
     * @type ko.computed<Boolean>
     */
    isValid : @computed ->
        !! @get('url') and _.contains @VALID_FORMATS, @get('format')
    
    
    /**
     * The reified dataset associated with this DataSource.
     * @type ko.asyncComputed<TimeSeriesData|CSVData>
     * @depends url, format
     */
    data : @asyncComputed ->
        return unless @isValid()
        
        format       = @get 'format'
        DataFileType = if format is 'csv' then CSVData else TimeSeriesData
        
        xhr = $.ajax do
            url      : @get 'url'
            dataType : if format is 'csv' then 'text' else 'json'
        
        promise = xhr.pipe (data) -> new DataFileType data
        promise.then do
            (data) ~> @trigger 'data-load',  this, data
            (err)  ~> @trigger 'data-error', this
        promise.xhr = xhr
        
        promise
    
    
    
    
    /**
     * Enforces backwards compatibility at runtime by converting a DataSource from
     * one of many of the historical "formats" we've used to whatever the modern
     * format looks like.
     * 
     * @param {Object} data Raw DataSource attributes to canonicalize.
     * @returns {Object} Converted raw data.
     */
    canonicalize : (data) ->
        data.shortName    or= data.name
        data.title        or= data.name
        data.subtitle     or= ''
        
        cols = data.columns
        if _.isArray cols
            data.columns = _.map cols, (col, idx) ->
                if _.isArray col
                    [label, type] = col
                    {idx, label, type or 'int'}
                else
                    col.type or= 'int'
                    col
        else
            cols = _.merge { ids:[], types:[] }, cols
            data.columns = _.map cols.labels, (label, idx) ->
                id   = cols.ids[idx]   or _.str.underscored(label.toLowerCase())
                type = cols.types[idx] or 'int'
                {id, idx, label, type}
        data
    
    


### DataSource Cache

ReadyEmitter.decorate DataSource

ALL_SOURCES = {}
DataSourceCache = exports.DataSourceCache = new ModelCache DataSource, {-ready, cache:ALL_SOURCES}

# Fetch all DataSources
DataSource.fetchAll = ->
    limn = require '../index'
    $.getJSON limn.mount('datasources/all'), (models) ->
        _.each models, (data) ->
            DataSourceCache.register new DataSource data
        
        # Trigger event when the DataSource TOC is ready
        DataSourceCache.ready true
        DataSource.ready true

DataSource.getAllSources = ->
    _.map ALL_SOURCES, op.I
